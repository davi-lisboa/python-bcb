{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa594d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# from bcb import sgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d2ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from io import StringIO\n",
    "from typing import Dict, Generator, List, Optional, Tuple, TypeAlias, Union\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from bcb.utils import Date, DateInput\n",
    "\n",
    "\"\"\"\n",
    "Sistema Gerenciador de Séries Temporais (SGS)\n",
    "\n",
    "O módulo ``sgs`` obtem os dados do webservice do Banco Central,\n",
    "interface json do serviço BCData/SGS -\n",
    "`Sistema Gerenciador de Séries Temporais (SGS)\n",
    "<https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaLocalizarSeries>`_.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class SGSCode:\n",
    "    def __init__(self, code: Union[str, int], name: Optional[str] = None) -> None:\n",
    "        if name is None:\n",
    "            if isinstance(code, int) or isinstance(code, str):\n",
    "                self.name = str(code)\n",
    "                self.value = int(code)\n",
    "        else:\n",
    "            self.name = str(name)\n",
    "            self.value = int(code)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.code} - {self.name}\" if self.name else f\"{self.code}\"\n",
    "\n",
    "\n",
    "SGSCodeInput: TypeAlias = Union[\n",
    "    int,\n",
    "    str,\n",
    "    Tuple[str, Union[int, str]],\n",
    "    List[Union[int, str, Tuple[str, Union[int, str]]]],\n",
    "    Dict[str, Union[int, str]],\n",
    "]\n",
    "\n",
    "\n",
    "def _codes(codes: SGSCodeInput) -> Generator[SGSCode, None, None]:\n",
    "    if isinstance(codes, int) or isinstance(codes, str):\n",
    "        yield SGSCode(codes)\n",
    "    elif isinstance(codes, tuple):\n",
    "        yield SGSCode(codes[1], codes[0])\n",
    "    elif isinstance(codes, list):\n",
    "        for cd in codes:\n",
    "            _ist = isinstance(cd, tuple)\n",
    "            yield SGSCode(cd[1], cd[0]) if _ist else SGSCode(cd)\n",
    "    elif isinstance(codes, dict):\n",
    "        for name, code in codes.items():\n",
    "            yield SGSCode(code, name)\n",
    "\n",
    "\n",
    "def _get_url_and_payload(code: int, start_date: DateInput, end_date: DateInput, last: int) -> Dict[str, str]:\n",
    "    payload = {\"formato\": \"json\"}\n",
    "    if last == 0:\n",
    "        if start_date is not None or end_date is not None:\n",
    "            payload[\"dataInicial\"] = Date(start_date).date.strftime(\"%d/%m/%Y\")\n",
    "            end_date = end_date if end_date else \"today\"\n",
    "            payload[\"dataFinal\"] = Date(end_date).date.strftime(\"%d/%m/%Y\")\n",
    "        url = \"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{}/dados\".format(code)\n",
    "    else:\n",
    "        url = (\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{}/dados\" \"/ultimos/{}\").format(code, last)\n",
    "\n",
    "    return {\"payload\": payload, \"url\": url}\n",
    "\n",
    "\n",
    "def _format_df(df: pd.DataFrame, code: SGSCode, freq: str) -> pd.DataFrame:\n",
    "    cns = {\"data\": \"Date\", \"valor\": code.name, \"datafim\": \"enddate\"}\n",
    "    df = df.rename(columns=cns)\n",
    "    if \"Date\" in df:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\")\n",
    "    if \"enddate\" in df:\n",
    "        df[\"enddate\"] = pd.to_datetime(df[\"enddate\"], format=\"%d/%m/%Y\")\n",
    "    df = df.set_index(\"Date\")\n",
    "    if freq:\n",
    "        df.index = df.index.to_period(freq)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6851ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(\n",
    "    codes: SGSCodeInput,\n",
    "    start: Optional[DateInput] = None,\n",
    "    end: Optional[DateInput] = None,\n",
    "    last: int = 0,\n",
    "    multi: bool = True,\n",
    "    freq: Optional[str] = None,\n",
    ") -> Union[pd.DataFrame, List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame pandas com séries temporais obtidas do SGS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    codes : {int, List[int], List[str], Dict[str:int]}\n",
    "        Este argumento pode ser uma das opções:\n",
    "\n",
    "        * ``int`` : código da série temporal\n",
    "        * ``list`` ou ``tuple`` : lista ou tupla com códigos\n",
    "        * ``list`` ou ``tuple`` : lista ou tupla com pares ``('nome', código)``\n",
    "        * ``dict`` : dicionário com pares ``{'nome': código}``\n",
    "\n",
    "        Com códigos numéricos é interessante utilizar os nomes com os códigos\n",
    "        para definir os nomes nas colunas das séries temporais.\n",
    "    start : str, int, date, datetime, Timestamp\n",
    "        Data de início da série.\n",
    "        Interpreta diferentes tipos e formatos de datas.\n",
    "    end : string, int, date, datetime, Timestamp\n",
    "        Data final da série.\n",
    "        Interpreta diferentes tipos e formatos de datas.\n",
    "    last : int\n",
    "        Retorna os últimos ``last`` elementos disponíveis da série temporal\n",
    "        solicitada. Se ``last`` for maior que 0 (zero) os argumentos ``start``\n",
    "        e ``end`` são ignorados.\n",
    "    multi : bool\n",
    "        Define se, quando mais de 1 série for solicitada, a função retorna uma\n",
    "        série multivariada ou uma lista com séries univariadas.\n",
    "    freq : str\n",
    "        Define a frequência a ser utilizada na série temporal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    ``DataFrame`` :\n",
    "        série temporal univariada ou multivariada,\n",
    "        quando solicitado mais de uma série (parâmetro ``multi=True``).\n",
    "\n",
    "    ``list`` :\n",
    "        lista com séries temporais univariadas,\n",
    "        quando solicitado mais de uma série (parâmetro ``multi=False``).\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for code in _codes(codes):\n",
    "        text = get_json(code.value, start, end, last)\n",
    "        df = pd.read_json(StringIO(text))\n",
    "        df = _format_df(df, code, freq)\n",
    "\n",
    "        if check_years_interval(start, end) is True:\n",
    "            df.sort_index(inplace=True)\n",
    "            df = df.loc[start:]\n",
    "            df = df.reset_index().drop_duplicates().set_index('Date')\n",
    "\n",
    "        dfs.append(df)\n",
    "    if len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "    else:\n",
    "        if multi:\n",
    "            return pd.concat(dfs, axis=1)\n",
    "        else:\n",
    "            return dfs\n",
    "\n",
    "def check_dates(start, end):\n",
    "    if start is None:\n",
    "        raise Exception(\"Date Error: Informe a data de início da(s) série(s).\")\n",
    "    if end is None:\n",
    "        end = dt.date.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    return start, end\n",
    "\n",
    "def check_years_interval(start: Optional[DateInput] = None, end: Optional[DateInput] = None, limit:int=8):\n",
    "    \n",
    "    start, end = check_dates(start, end)\n",
    "\n",
    "    start_as_date = dt.datetime.strptime(start, '%Y-%m-%d').date() if type(start) == str else start\n",
    "    end_as_date = dt.datetime.strptime(end, '%Y-%m-%d').date() if type(end) == str else end\n",
    "    \n",
    "    diff_years = (end_as_date - start_as_date).days / 365\n",
    "\n",
    "    return diff_years > limit\n",
    "\n",
    "\n",
    "def create_time_chunks(start: Optional[DateInput] = None, end: Optional[DateInput] = None, step: int = 5):\n",
    "        start, end = check_dates(start, end)\n",
    "\n",
    "        start_as_date = dt.datetime.strptime(start, '%Y-%m-%d').date() if type(start) == str else start\n",
    "        end_as_date = dt.datetime.strptime(end, '%Y-%m-%d').date() if type(end) == str else end\n",
    "        \n",
    "        previous_start_year = (start_as_date - pd.offsets.YearBegin(1)).date()\n",
    "        next_end_year = (end_as_date + pd.offsets.YearBegin(0)).date()\n",
    "\n",
    "        date_range = pd.date_range( start=previous_start_year, \n",
    "                                    end=next_end_year, \n",
    "                                    freq=f'{step}YS', \n",
    "                                    inclusive='left').to_list()\n",
    "\n",
    "        date_range = date_range + [end_as_date]\n",
    "\n",
    "        return date_range\n",
    "\n",
    "def get_json(code: int, start: Optional[DateInput] = None, end: Optional[DateInput] = None, last: int = 0) -> str:\n",
    "    \"\"\"\n",
    "    Retorna um JSON com séries temporais obtidas do SGS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    code : int\n",
    "        Código da série temporal\n",
    "    start : str, int, date, datetime, Timestamp\n",
    "        Data de início da série.\n",
    "        Interpreta diferentes tipos e formatos de datas.\n",
    "    end : string, int, date, datetime, Timestamp\n",
    "        Data final da série.\n",
    "        Interpreta diferentes tipos e formatos de datas.\n",
    "    last : int\n",
    "        Retorna os últimos ``last`` elementos disponíveis da série temporal\n",
    "        solicitada. Se ``last`` for maior que 0 (zero) os argumentos ``start``\n",
    "        e ``end`` são ignorados.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    JSON :\n",
    "        série temporal univariada em formato JSON.\n",
    "    \"\"\"\n",
    "    start, end = check_dates(start, end)\n",
    "\n",
    "    # try: \n",
    "    #     check_years_interval(start, end)\n",
    "\n",
    "    # except:\n",
    "    #     raise Exception(\"Date Error: Informe as datas de início e fim da(s) série(s).\")\n",
    "\n",
    "    \n",
    "    # if check_years_interval(start, end) is True:  \n",
    "        \n",
    "    #     date_range = create_time_chunks(start, end, step=5)\n",
    "\n",
    "    #     final_json = []\n",
    "    #     for i_dates in range( len(date_range)-1 ):\n",
    "    #         current_start = date_range[i_dates].strftime('%Y-%m-%d')\n",
    "    #         current_end = date_range[i_dates + 1].strftime('%Y-%m-%d')\n",
    "    #         print('Start:', current_start, '|', 'End:', current_end)\n",
    "\n",
    "    #         urd = _get_url_and_payload(code, current_start, current_end, last)\n",
    "    #         res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "    #         if res.status_code != 200:\n",
    "    #             try:\n",
    "    #                 res_json = json.loads(res.text)\n",
    "    #             except Exception:\n",
    "    #                 res_json = {}\n",
    "    #             if \"error\" in res_json:\n",
    "    #                 raise Exception(\"BCB error: {}\".format(res_json[\"error\"]))\n",
    "    #             elif \"erro\" in res_json:\n",
    "    #                 raise Exception(\"BCB error: {}\".format(res_json[\"erro\"][\"detail\"]))\n",
    "    #             raise Exception(\"Download error: code = {}\".format(code))\n",
    "\n",
    "    #         final_json = final_json + res.text.replace('[', '').replace(']', '').split(',')\n",
    "    #     final_json = '[' + ','.join(final_json) + ']'\n",
    "\n",
    "    #     return final_json\n",
    "\n",
    "    urd = _get_url_and_payload(code, start, end, last)\n",
    "    res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "    if res.status_code != 200:\n",
    "        try:\n",
    "            res_json = json.loads(res.text)\n",
    "        except Exception:\n",
    "            res_json = {}\n",
    "        if \"error\" in res_json:\n",
    "            # raise Exception(\"BCB error: {}\".format(res_json[\"error\"]))\n",
    "            if check_years_interval(start, end) is True:  \n",
    "        \n",
    "                date_range = create_time_chunks(start, end, step=5)\n",
    "\n",
    "                final_json = []\n",
    "                for i_dates in range( len(date_range)-1 ):\n",
    "                    current_start = date_range[i_dates].strftime('%Y-%m-%d')\n",
    "                    current_end = date_range[i_dates + 1].strftime('%Y-%m-%d')\n",
    "                    print('Start:', current_start, '|', 'End:', current_end)\n",
    "\n",
    "                    urd = _get_url_and_payload(code, current_start, current_end, last)\n",
    "                    res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "                    if res.status_code != 200:\n",
    "                        try:\n",
    "                            res_json = json.loads(res.text)\n",
    "                        except Exception:\n",
    "                            res_json = {}\n",
    "                    final_json = final_json + res.text.replace('[', '').replace(']', '').split(',')\n",
    "            final_json = '[' + ','.join(final_json) + ']'\n",
    "            return final_json\n",
    "\n",
    "        elif \"erro\" in res_json:\n",
    "            raise Exception(\"BCB error: {}\".format(res_json[\"erro\"][\"detail\"]))\n",
    "        raise Exception(\"Download error: code = {}\".format(code))\n",
    "    return res.text\n",
    "    # return start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1031f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. IMPORTAÇÕES ---\n",
    "import json as json_parser\n",
    "from io import StringIO\n",
    "from typing import Dict, Generator, List, Optional, Tuple, TypeAlias, Union\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from bcb.utils import Date, DateInput\n",
    "\n",
    "\n",
    "# --- 2. CLASSES E FUNÇÕES ORIGINAIS DA BIBLIOTECA (sem alterações) ---\n",
    "class SGSCode:\n",
    "    def __init__(self, code: Union[str, int], name: Optional[str] = None) -> None:\n",
    "        if name is None:\n",
    "            if isinstance(code, int) or isinstance(code, str):\n",
    "                self.name = str(code)\n",
    "                self.value = int(code)\n",
    "        else:\n",
    "            self.name = str(name)\n",
    "            self.value = int(code)\n",
    "    def __repr__(self):\n",
    "        return f\"{self.value} - {self.name}\" if self.name else f\"{self.value}\"\n",
    "\n",
    "SGSCodeInput: TypeAlias = Union[int, str, Tuple[str, Union[int, str]], List[Union[int, str, Tuple[str, Union[int, str]]]], Dict[str, Union[int, str]],]\n",
    "\n",
    "def _codes(codes: SGSCodeInput) -> Generator[SGSCode, None, None]:\n",
    "    if isinstance(codes, int) or isinstance(codes, str):\n",
    "        yield SGSCode(codes)\n",
    "    elif isinstance(codes, tuple):\n",
    "        yield SGSCode(codes[1], codes[0])\n",
    "    elif isinstance(codes, list):\n",
    "        for cd in codes:\n",
    "            _ist = isinstance(cd, tuple)\n",
    "            yield SGSCode(cd[1], cd[0]) if _ist else SGSCode(cd)\n",
    "    elif isinstance(codes, dict):\n",
    "        for name, code in codes.items():\n",
    "            yield SGSCode(code, name)\n",
    "\n",
    "def _get_url_and_payload(code: int, start_date: Optional[DateInput], end_date: Optional[DateInput], last: int) -> Dict[str, str]:\n",
    "    payload = {\"formato\": \"json\"}\n",
    "    if last == 0:\n",
    "        if start_date is not None or end_date is not None:\n",
    "            payload[\"dataInicial\"] = Date(start_date).date.strftime(\"%d/%m/%Y\")\n",
    "            end_date = end_date if end_date else \"today\"\n",
    "            payload[\"dataFinal\"] = Date(end_date).date.strftime(\"%d/%m/%Y\")\n",
    "        url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados\"\n",
    "    else:\n",
    "        url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados/ultimos/{last}\"\n",
    "    return {\"payload\": payload, \"url\": url}\n",
    "\n",
    "def _format_df(df: pd.DataFrame, code: SGSCode, freq: str) -> pd.DataFrame:\n",
    "    cns = {\"data\": \"Date\", \"valor\": code.name, \"datafim\": \"enddate\"}\n",
    "    df = df.rename(columns=cns)\n",
    "    if \"Date\" in df:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n",
    "    if \"enddate\" in df:\n",
    "        df[\"enddate\"] = pd.to_datetime(df[\"enddate\"], dayfirst=True)\n",
    "    df = df.set_index(\"Date\")\n",
    "    if freq:\n",
    "        df.index = df.index.to_period(freq)\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. FUNÇÕES NOVAS E REATORADAS COM A LÓGICA HÍBRIDA ---\n",
    "\n",
    "def _probe_is_daily(code: int) -> bool:\n",
    "    try:\n",
    "        urd = _get_url_and_payload(code, None, None, last=2)\n",
    "        res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "        res.raise_for_status()\n",
    "        data = json_parser.loads(res.text)\n",
    "        if len(data) < 2: return False\n",
    "        date_format = \"%d/%m/%Y\"\n",
    "        last_date = dt.datetime.strptime(data[1]['data'], date_format).date()\n",
    "        penultimate_date = dt.datetime.strptime(data[0]['data'], date_format).date()\n",
    "        return (last_date - penultimate_date).days == 1\n",
    "    except (requests.RequestException, IndexError, KeyError, ValueError):\n",
    "        return True\n",
    "\n",
    "def _fetch_sgs_json(code: int, start: Optional[DateInput], end: Optional[DateInput], last: int) -> str:\n",
    "    urd = _get_url_and_payload(code, start, end, last)\n",
    "    res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "    res.raise_for_status()\n",
    "    return res.text\n",
    "\n",
    "def _fetch_in_chunks(code: int, start_date: dt.date, end_date: dt.date) -> pd.DataFrame:\n",
    "    df_list = []\n",
    "    current_start = start_date\n",
    "    while current_start < end_date:\n",
    "        current_end = current_start + relativedelta(years=5)\n",
    "        if current_end > end_date:\n",
    "            current_end = end_date\n",
    "        try:\n",
    "            json_text = _fetch_sgs_json(code, current_start, current_end, 0)\n",
    "            if json_text:\n",
    "                chunk_df = pd.read_json(StringIO(json_text), orient='records')\n",
    "                if not chunk_df.empty:\n",
    "                    df_list.append(chunk_df)\n",
    "        except (json_parser.JSONDecodeError, requests.exceptions.HTTPError):\n",
    "            pass # Ignora blocos com resposta vazia ou erros\n",
    "        current_start = current_end + relativedelta(days=1)\n",
    "    if not df_list:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# AJUSTE FINAL E DEFINITIVO ESTÁ NESTA FUNÇÃO\n",
    "def get_json_as_df(code: int, start: Optional[DateInput] = None, end: Optional[DateInput] = None, last: int = 0) -> pd.DataFrame:\n",
    "    if last > 0:\n",
    "        text = _fetch_sgs_json(code, None, None, last)\n",
    "        return pd.read_json(StringIO(text), orient='records')\n",
    "\n",
    "    if start:\n",
    "        start_date = pd.to_datetime(start).date()\n",
    "        end_date = pd.to_datetime(end or dt.date.today()).date()\n",
    "        is_long_period = (end_date - start_date).days > 3600\n",
    "        if is_long_period and _probe_is_daily(code):\n",
    "            print(f\"Série {code}: Período longo e diário detectado. Buscando em blocos...\")\n",
    "            return _fetch_in_chunks(code, start_date, end_date)\n",
    "        text = _fetch_sgs_json(code, start_date, end_date, 0)\n",
    "        return pd.read_json(StringIO(text), orient='records')\n",
    "    else:\n",
    "        # Tenta o caminho otimista. Se falhar por erro de HTTP ou por erro de parsing do pandas,\n",
    "        # cai no fallback robusto de busca em blocos.\n",
    "        try:\n",
    "            text = _fetch_sgs_json(code, None, None, 0)\n",
    "            return pd.read_json(StringIO(text), orient='records')\n",
    "        except (requests.exceptions.HTTPError, ValueError):\n",
    "            print(f\"Série {code}: Requisição inicial falhou ou resultado inválido. Reiniciando busca em blocos...\")\n",
    "            start_date = dt.date(1980, 1, 1)\n",
    "            end_date = dt.date.today()\n",
    "            return _fetch_in_chunks(code, start_date, end_date)\n",
    "\n",
    "# --- 4. FUNÇÃO 'get' FINAL ---\n",
    "\n",
    "def get(\n",
    "    codes: SGSCodeInput,\n",
    "    start: Optional[DateInput] = None,\n",
    "    end: Optional[DateInput] = None,\n",
    "    last: int = 0,\n",
    "    multi: bool = True,\n",
    "    freq: Optional[str] = None,\n",
    ") -> Union[pd.DataFrame, List[pd.DataFrame]]:\n",
    "    dfs = []\n",
    "    for code in _codes(codes):\n",
    "        raw_df = get_json_as_df(code.value, start, end, last)\n",
    "        if raw_df.empty:\n",
    "            continue\n",
    "        df = _format_df(raw_df, code, freq)\n",
    "        if not df.index.is_unique:\n",
    "            df = df.loc[~df.index.duplicated(keep='first')]\n",
    "        if start:\n",
    "            start_date_dt = pd.to_datetime(start)\n",
    "            df = df.loc[df.index >= start_date_dt]\n",
    "        dfs.append(df)\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    if len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "    else:\n",
    "        if multi:\n",
    "            return pd.concat(dfs, axis=1)\n",
    "        else:\n",
    "            return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ff19acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. IMPORTAÇÕES ---\n",
    "import json as json_parser\n",
    "from io import StringIO\n",
    "from typing import Dict, Generator, List, Optional, Tuple, TypeAlias, Union\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from bcb.utils import Date, DateInput\n",
    "\n",
    "\n",
    "# --- 2. CLASSES E FUNÇÕES DE BASE ---\n",
    "class SGSCode:\n",
    "    \"\"\"Representa um código de série temporal do SGS com nome e valor.\"\"\"\n",
    "    def __init__(self, code: Union[str, int], name: Optional[str] = None) -> None:\n",
    "        if name is None:\n",
    "            if isinstance(code, int) or isinstance(code, str):\n",
    "                self.name = str(code)\n",
    "                self.value = int(code)\n",
    "        else:\n",
    "            self.name = str(name)\n",
    "            self.value = int(code)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.value} - {self.name}\" if self.name else f\"{self.value}\"\n",
    "\n",
    "\n",
    "SGSCodeInput: TypeAlias = Union[int, str, Tuple[str, Union[int, str]], List[Union[int, str, Tuple[str, Union[int, str]]]], Dict[str, Union[int, str]],]\n",
    "\n",
    "\n",
    "def _codes(codes: SGSCodeInput) -> Generator[SGSCode, None, None]:\n",
    "    \"\"\"\n",
    "    Normaliza diferentes formatos de entrada de códigos de séries em um gerador\n",
    "    de objetos SGSCode.\n",
    "    \"\"\"\n",
    "    if isinstance(codes, int) or isinstance(codes, str):\n",
    "        yield SGSCode(codes)\n",
    "    elif isinstance(codes, tuple):\n",
    "        yield SGSCode(codes[1], codes[0])\n",
    "    elif isinstance(codes, list):\n",
    "        for cd in codes:\n",
    "            _ist = isinstance(cd, tuple)\n",
    "            yield SGSCode(cd[1], cd[0]) if _ist else SGSCode(cd)\n",
    "    elif isinstance(codes, dict):\n",
    "        for name, code in codes.items():\n",
    "            yield SGSCode(code, name)\n",
    "\n",
    "\n",
    "def _get_url_and_payload(code: int, start_date: Optional[DateInput], end_date: Optional[DateInput], last: int) -> Dict[str, str]:\n",
    "    \"\"\"Monta a URL e os parâmetros para a chamada à API do SGS.\"\"\"\n",
    "    payload = {\"formato\": \"json\"}\n",
    "    if last == 0:\n",
    "        if start_date is not None or end_date is not None:\n",
    "            payload[\"dataInicial\"] = Date(start_date).date.strftime(\"%d/%m/%Y\")\n",
    "            end_date = end_date if end_date else \"today\"\n",
    "            payload[\"dataFinal\"] = Date(end_date).date.strftime(\"%d/%m/%Y\")\n",
    "        url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados\"\n",
    "    else:\n",
    "        url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados/ultimos/{last}\"\n",
    "    return {\"payload\": payload, \"url\": url}\n",
    "\n",
    "\n",
    "def _format_df(df: pd.DataFrame, code: SGSCode, freq: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Formata o DataFrame bruto retornado pela API, renomeando colunas,\n",
    "    convertendo tipos de dados e definindo o índice.\n",
    "    \"\"\"\n",
    "    cns = {\"data\": \"Date\", \"valor\": code.name, \"datafim\": \"enddate\"}\n",
    "    df = df.rename(columns=cns)\n",
    "    if \"Date\" in df:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n",
    "    if \"enddate\" in df:\n",
    "        df[\"enddate\"] = pd.to_datetime(df[\"enddate\"], dayfirst=True)\n",
    "    df = df.set_index(\"Date\")\n",
    "    if freq:\n",
    "        df.index = df.index.to_period(freq)\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- 3. FUNÇÕES AUXILIARES PARA A LÓGICA DE BUSCA AVANÇADA ---\n",
    "\n",
    "def _probe_is_daily(code: int) -> bool:\n",
    "    \"\"\"\n",
    "    Sonda a API buscando os 2 últimos pontos para determinar se a série é diária.\n",
    "    A verificação é feita calculando a diferença em dias entre os dois últimos pontos.\n",
    "\n",
    "    Args:\n",
    "        code (int): O código da série a ser verificada.\n",
    "\n",
    "    Returns:\n",
    "        bool: True se a diferença for de 1 dia (indicando série diária),\n",
    "              False caso contrário. Em caso de erro, assume True por segurança.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pede os dois últimos pontos da série para inferir a frequência.\n",
    "        urd = _get_url_and_payload(code, None, None, last=2)\n",
    "        res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "        res.raise_for_status()\n",
    "        data = json_parser.loads(res.text)\n",
    "\n",
    "        # Se houver menos de 2 pontos, não é possível inferir a frequência.\n",
    "        if len(data) < 2:\n",
    "            return False\n",
    "\n",
    "        # Converte as datas (formato \"DD/MM/YYYY\") e calcula a diferença.\n",
    "        date_format = \"%d/%m/%Y\"\n",
    "        last_date = dt.datetime.strptime(data[1]['data'], date_format).date()\n",
    "        penultimate_date = dt.datetime.strptime(data[0]['data'], date_format).date()\n",
    "        delta_days = (last_date - penultimate_date).days\n",
    "        return delta_days <= 20\n",
    "    except (requests.RequestException, IndexError, KeyError, ValueError):\n",
    "        # Se a sondagem falhar, assume o pior cenário (série diária) para\n",
    "        # garantir que a busca em blocos seja acionada se o período for longo.\n",
    "        return True\n",
    "\n",
    "\n",
    "def _fetch_sgs_json(code: int, start: Optional[DateInput], end: Optional[DateInput], last: int) -> str:\n",
    "    \"\"\"\n",
    "    Executa uma única requisição HTTP para a API do SGS e retorna o JSON como texto.\n",
    "\n",
    "    Args:\n",
    "        code (int): Código da série.\n",
    "        start (DateInput, optional): Data de início.\n",
    "        end (DateInput, optional): Data de fim.\n",
    "        last (int): Número de últimas observações a serem retornadas.\n",
    "\n",
    "    Returns:\n",
    "        str: A resposta da API em formato JSON de texto.\n",
    "    \"\"\"\n",
    "    urd = _get_url_and_payload(code, start, end, last)\n",
    "    res = requests.get(urd[\"url\"], params=urd[\"payload\"])\n",
    "    res.raise_for_status()  # Lança um erro para status HTTP de falha (4xx ou 5xx)\n",
    "    return res.text\n",
    "\n",
    "\n",
    "def _fetch_in_chunks(code: int, start_date: dt.date, end_date: dt.date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Busca os dados de uma série em blocos de tempo para contornar limites da API.\n",
    "    Converte cada bloco em um DataFrame e os concatena no final.\n",
    "\n",
    "    Args:\n",
    "        code (int): Código da série.\n",
    "        start_date (dt.date): Data de início do período total.\n",
    "        end_date (dt.date): Data de fim do período total.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um DataFrame contendo todos os dados do período solicitado.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    current_start = start_date\n",
    "    while current_start < end_date:\n",
    "        # Define o fim do bloco (chunk) atual.\n",
    "        current_end = current_start + relativedelta(years=5)\n",
    "        if current_end > end_date:\n",
    "            current_end = end_date\n",
    "        \n",
    "        try:\n",
    "            json_text = _fetch_sgs_json(code, current_start, current_end, 0)\n",
    "            if json_text:\n",
    "                # Converte o JSON do bloco em um DataFrame e o adiciona à lista.\n",
    "                chunk_df = pd.read_json(StringIO(json_text), orient='records')\n",
    "                if not chunk_df.empty:\n",
    "                    df_list.append(chunk_df)\n",
    "        except (json_parser.JSONDecodeError, requests.exceptions.HTTPError):\n",
    "            # Ignora blocos que retornam resposta vazia ou com erro, continuando o processo.\n",
    "            pass\n",
    "            \n",
    "        # Avança para o próximo bloco.\n",
    "        current_start = current_end + relativedelta(days=1)\n",
    "    \n",
    "    if not df_list:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "def get_json_as_df(code: int, start: Optional[DateInput] = None, end: Optional[DateInput] = None, last: int = 0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Função central que orquestra a busca de dados, decidindo entre uma busca\n",
    "    única ou em blocos, e sempre retorna um DataFrame.\n",
    "\n",
    "    Args:\n",
    "        code (int): Código da série.\n",
    "        start (DateInput, optional): Data de início.\n",
    "        end (DateInput, optional): Data de fim.\n",
    "        last (int): Número de últimas observações.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados brutos da série (\"data\", \"valor\").\n",
    "    \"\"\"\n",
    "    # Caso 1: Busca pelas últimas 'n' observações.\n",
    "    if last > 0:\n",
    "        text = _fetch_sgs_json(code, None, None, last)\n",
    "        return pd.read_json(StringIO(text), orient='records')\n",
    "\n",
    "    # Caso 2: Datas de início e fim são fornecidas.\n",
    "    if start:\n",
    "        start_date = pd.to_datetime(start).date()\n",
    "        end_date = pd.to_datetime(end or dt.date.today()).date()\n",
    "        is_long_period = (end_date - start_date).days > 3600\n",
    "        \n",
    "        # Lógica proativa: se o período for longo, sonda a frequência.\n",
    "        if is_long_period and _probe_is_daily(code):\n",
    "            return _fetch_in_chunks(code, start_date, end_date)\n",
    "        \n",
    "        # Se não for longo ou não for diário, faz uma busca única.\n",
    "        text = _fetch_sgs_json(code, start_date, end_date, 0)\n",
    "        return pd.read_json(StringIO(text), orient='records')\n",
    "    \n",
    "    # Caso 3: Nenhuma data fornecida (busca a série completa).\n",
    "    else:\n",
    "        # Lógica reativa: tenta a busca completa. Se falhar, assume que é uma\n",
    "        # série diária longa e recorre à busca em blocos.\n",
    "        try:\n",
    "            text = _fetch_sgs_json(code, None, None, 0)\n",
    "            return pd.read_json(StringIO(text), orient='records')\n",
    "        except (requests.exceptions.HTTPError, ValueError):\n",
    "            # O fallback inicia a busca a partir de uma data antiga e segura.\n",
    "            start_date = dt.date(1980, 1, 1)\n",
    "            end_date = dt.date.today()\n",
    "            return _fetch_in_chunks(code, start_date, end_date)\n",
    "\n",
    "\n",
    "# --- 4. FUNÇÃO PRINCIPAL (INTERFACE PÚBLICA) ---\n",
    "\n",
    "def get(\n",
    "    codes: SGSCodeInput,\n",
    "    start: Optional[DateInput] = None,\n",
    "    end: Optional[DateInput] = None,\n",
    "    last: int = 0,\n",
    "    multi: bool = True,\n",
    "    freq: Optional[str] = None,\n",
    ") -> Union[pd.DataFrame, List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame pandas com séries temporais obtidas do SGS.\n",
    "    Esta função contorna a limitação de 10 anos para séries diárias ao\n",
    "    realizar múltiplas requisições em blocos quando necessário.\n",
    "\n",
    "    Args:\n",
    "        codes ({int, str, list, dict}): Código(s) da(s) série(s) a ser(em) consultada(s).\n",
    "        start (DateInput, optional): Data de início da série.\n",
    "        end (DateInput, optional): Data de fim da série.\n",
    "        last (int, optional): Retorna os 'n' últimos dados disponíveis.\n",
    "        multi (bool, optional): Se True, retorna um único DataFrame para múltiplas\n",
    "                                séries. Se False, uma lista de DataFrames.\n",
    "        freq (str, optional): Frequência a ser utilizada no índice do DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame, List[pd.DataFrame]]: DataFrame (ou lista de DataFrames)\n",
    "                                                 com as séries temporais.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for code in _codes(codes):\n",
    "        # A função get_json_as_df abstrai toda a complexidade da busca.\n",
    "        raw_df = get_json_as_df(code.value, start, end, last)\n",
    "        \n",
    "        if raw_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Formata o DataFrame bruto para o padrão final.\n",
    "        df = _format_df(raw_df, code, freq)\n",
    "        \n",
    "        # Garante a remoção de duplicatas no índice (uma camada extra de segurança).\n",
    "        if not df.index.is_unique:\n",
    "            df = df.loc[~df.index.duplicated(keep='first')]\n",
    "        \n",
    "        # Garante que os dados retornados comecem na data de início solicitada.\n",
    "        if start:\n",
    "            start_date_dt = pd.to_datetime(start)\n",
    "            df = df.loc[df.index >= start_date_dt]\n",
    "        \n",
    "        dfs.append(df)\n",
    "        \n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "    else:\n",
    "        if multi:\n",
    "            return pd.concat(dfs, axis=1)\n",
    "        else:\n",
    "            return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71d6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2858"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_json(433, start='2009-03-17', end='2025-07-17'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e711cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"data\":\"01/03/2019\",\"valor\":\"0.75\"},{\"data\":\"01/04/2019\",\"valor\":\"0.57\"},{\"data\":\"01/05/2019\",\"valor\":\"0.13\"},{\"data\":\"01/06/2019\",\"valor\":\"0.01\"},{\"data\":\"01/07/2019\",\"valor\":\"0.19\"},{\"data\":\"01/08/2019\",\"valor\":\"0.11\"},{\"data\":\"01/09/2019\",\"valor\":\"-0.04\"},{\"data\":\"01/10/2019\",\"valor\":\"0.10\"},{\"data\":\"01/11/2019\",\"valor\":\"0.51\"},{\"data\":\"01/12/2019\",\"valor\":\"1.15\"},{\"data\":\"01/01/2020\",\"valor\":\"0.21\"},{\"data\":\"01/02/2020\",\"valor\":\"0.25\"},{\"data\":\"01/03/2020\",\"valor\":\"0.07\"},{\"data\":\"01/04/2020\",\"valor\":\"-0.31\"},{\"data\":\"01/05/2020\",\"valor\":\"-0.38\"},{\"data\":\"01/06/2020\",\"valor\":\"0.26\"},{\"data\":\"01/07/2020\",\"valor\":\"0.36\"},{\"data\":\"01/08/2020\",\"valor\":\"0.24\"},{\"data\":\"01/09/2020\",\"valor\":\"0.64\"},{\"data\":\"01/10/2020\",\"valor\":\"0.86\"},{\"data\":\"01/11/2020\",\"valor\":\"0.89\"},{\"data\":\"01/12/2020\",\"valor\":\"1.35\"},{\"data\":\"01/01/2021\",\"valor\":\"0.25\"},{\"data\":\"01/02/2021\",\"valor\":\"0.86\"},{\"data\":\"01/03/2021\",\"valor\":\"0.93\"},{\"data\":\"01/04/2021\",\"valor\":\"0.31\"},{\"data\":\"01/05/2021\",\"valor\":\"0.83\"},{\"data\":\"01/06/2021\",\"valor\":\"0.53\"},{\"data\":\"01/07/2021\",\"valor\":\"0.96\"},{\"data\":\"01/08/2021\",\"valor\":\"0.87\"},{\"data\":\"01/09/2021\",\"valor\":\"1.16\"},{\"data\":\"01/10/2021\",\"valor\":\"1.25\"},{\"data\":\"01/11/2021\",\"valor\":\"0.95\"},{\"data\":\"01/12/2021\",\"valor\":\"0.73\"},{\"data\":\"01/01/2022\",\"valor\":\"0.54\"},{\"data\":\"01/02/2022\",\"valor\":\"1.01\"},{\"data\":\"01/03/2022\",\"valor\":\"1.62\"},{\"data\":\"01/04/2022\",\"valor\":\"1.06\"},{\"data\":\"01/05/2022\",\"valor\":\"0.47\"},{\"data\":\"01/06/2022\",\"valor\":\"0.67\"},{\"data\":\"01/07/2022\",\"valor\":\"-0.68\"},{\"data\":\"01/08/2022\",\"valor\":\"-0.36\"},{\"data\":\"01/09/2022\",\"valor\":\"-0.29\"},{\"data\":\"01/10/2022\",\"valor\":\"0.59\"},{\"data\":\"01/11/2022\",\"valor\":\"0.41\"},{\"data\":\"01/12/2022\",\"valor\":\"0.62\"},{\"data\":\"01/01/2023\",\"valor\":\"0.53\"},{\"data\":\"01/02/2023\",\"valor\":\"0.84\"},{\"data\":\"01/03/2023\",\"valor\":\"0.71\"},{\"data\":\"01/04/2023\",\"valor\":\"0.61\"},{\"data\":\"01/05/2023\",\"valor\":\"0.23\"},{\"data\":\"01/06/2023\",\"valor\":\"-0.08\"},{\"data\":\"01/07/2023\",\"valor\":\"0.12\"},{\"data\":\"01/08/2023\",\"valor\":\"0.23\"},{\"data\":\"01/09/2023\",\"valor\":\"0.26\"},{\"data\":\"01/10/2023\",\"valor\":\"0.24\"},{\"data\":\"01/11/2023\",\"valor\":\"0.28\"},{\"data\":\"01/12/2023\",\"valor\":\"0.56\"},{\"data\":\"01/01/2024\",\"valor\":\"0.42\"},{\"data\":\"01/02/2024\",\"valor\":\"0.83\"},{\"data\":\"01/03/2024\",\"valor\":\"0.16\"},{\"data\":\"01/04/2024\",\"valor\":\"0.38\"},{\"data\":\"01/05/2024\",\"valor\":\"0.46\"},{\"data\":\"01/06/2024\",\"valor\":\"0.21\"},{\"data\":\"01/07/2024\",\"valor\":\"0.38\"},{\"data\":\"01/08/2024\",\"valor\":\"-0.02\"},{\"data\":\"01/09/2024\",\"valor\":\"0.44\"},{\"data\":\"01/10/2024\",\"valor\":\"0.56\"},{\"data\":\"01/11/2024\",\"valor\":\"0.39\"},{\"data\":\"01/12/2024\",\"valor\":\"0.52\"},{\"data\":\"01/01/2025\",\"valor\":\"0.16\"},{\"data\":\"01/02/2025\",\"valor\":\"1.31\"},{\"data\":\"01/03/2025\",\"valor\":\"0.56\"},{\"data\":\"01/04/2025\",\"valor\":\"0.43\"},{\"data\":\"01/05/2025\",\"valor\":\"0.26\"},{\"data\":\"01/06/2025\",\"valor\":\"0.24\"},{\"data\":\"01/07/2025\",\"valor\":\"0.26\"}]'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json = get_json(433, start='2019-03-17', end='2025-07-17') \\\n",
    "    #.replace('[', '').replace(']', '')#.replace('{', '').replace('}', '') \\\n",
    "        # .split(',')\n",
    "\n",
    "json\n",
    "# for i in json: \n",
    "#     print(i)\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "afdf5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipca</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-01</th>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-01</th>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-01</th>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-01</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ipca\n",
       "Date            \n",
       "2000-04-01  0.42\n",
       "2000-05-01  0.01\n",
       "2000-06-01  0.23\n",
       "2000-07-01  1.61\n",
       "2000-08-01  1.31\n",
       "...          ...\n",
       "2025-03-01  0.56\n",
       "2025-04-01  0.43\n",
       "2025-05-01  0.26\n",
       "2025-06-01  0.24\n",
       "2025-07-01  0.26\n",
       "\n",
       "[304 rows x 1 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from bcb import sgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "series = dict(\n",
    "            # cambio=1, \n",
    "            # selic=11,\n",
    "            ipca=433\n",
    "            )\n",
    "\n",
    "df_bcb  = get(series, start='2000-03-17', end='2025-08-17')\n",
    "(\n",
    "    df_bcb\n",
    "    # .plot(subplots=True, figsize=(10,4))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "03917fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bcb#.reset_index().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46d6669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipca</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-08-11</th>\n",
       "      <td>5.4473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-12</th>\n",
       "      <td>5.4052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-13</th>\n",
       "      <td>5.3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>5.4095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-15</th>\n",
       "      <td>5.3928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ipca\n",
       "Date              \n",
       "2025-08-11  5.4473\n",
       "2025-08-12  5.4052\n",
       "2025-08-13  5.3928\n",
       "2025-08-14  5.4095\n",
       "2025-08-15  5.3928"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bcb import sgs\n",
    "\n",
    "sgs.get({'ipca':1}, last=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f380177",
   "metadata": {},
   "source": [
    "não faz sentido identificar se a série é diária ou não pelo número de '/'\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "from bcb import sgs\n",
    "\n",
    "sgs.get({'ipca':433}, last=1)\n",
    "\n",
    "```\n",
    "\n",
    "Retorna \n",
    "\n",
    "Data | ipca\n",
    "\n",
    "2025-07-01 | 0.26\n",
    "\n",
    " e é uma série mensal\n",
    "\n",
    "\n",
    "\n",
    "assim como\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "from bcb import sgs\n",
    "\n",
    "sgs.get({'cambio':1}, last=1)\n",
    "\n",
    "```\n",
    "\n",
    "retorna \n",
    "\n",
    "Data | ipca\n",
    "\n",
    "2025-08-15 | 5.3928\n",
    "\n",
    "\n",
    "\n",
    "e é diária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96fd7a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 1999-01-01 | End: 2004-01-01\n",
      "Start: 2004-01-01 | End: 2009-01-01\n",
      "Start: 2009-01-01 | End: 2014-01-01\n",
      "Start: 2014-01-01 | End: 2019-01-01\n",
      "Start: 2019-01-01 | End: 2024-01-01\n",
      "Start: 2024-01-01 | End: 2025-08-17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipca</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-01</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-01</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-01</th>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-01</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-01</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ipca\n",
       "Date            \n",
       "2000-01-01  0.62\n",
       "2000-02-01  0.13\n",
       "2000-03-01  0.22\n",
       "2000-04-01  0.42\n",
       "2000-05-01  0.01\n",
       "...          ...\n",
       "2025-03-01  0.56\n",
       "2025-04-01  0.43\n",
       "2025-05-01  0.26\n",
       "2025-06-01  0.24\n",
       "2025-07-01  0.26\n",
       "\n",
       "[307 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get({'ipca':433}, start = '2000-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f30eeeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "BCB error: br.gov.bcb.pec.sgs.comum.excecoes.SGSNegocioException: Value(s) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mipca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m433\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1899-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1904-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\bcb\\sgs\\__init__.py:137\u001b[0m, in \u001b[0;36mget\u001b[1;34m(codes, start, end, last, multi, freq)\u001b[0m\n\u001b[0;32m    135\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m _codes(codes):\n\u001b[1;32m--> 137\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(StringIO(text))\n\u001b[0;32m    139\u001b[0m     df \u001b[38;5;241m=\u001b[39m _format_df(df, code, freq)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\bcb\\sgs\\__init__.py:186\u001b[0m, in \u001b[0;36mget_json\u001b[1;34m(code, start, end, last)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBCB error: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(res_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merro\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res_json:\n\u001b[1;32m--> 186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBCB error: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(res_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merro\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload error: code = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(code))\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mException\u001b[0m: BCB error: br.gov.bcb.pec.sgs.comum.excecoes.SGSNegocioException: Value(s) not found"
     ]
    }
   ],
   "source": [
    "sgs.get({'ipca':433}, start='1899-01-01', end='1904-01-01' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ac1aad05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cambio</th>\n",
       "      <th>selic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>1.8011</td>\n",
       "      <td>0.069186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>1.8337</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>1.8544</td>\n",
       "      <td>0.069220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>1.8461</td>\n",
       "      <td>0.069286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-07</th>\n",
       "      <td>5.4638</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-11</th>\n",
       "      <td>5.4473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-12</th>\n",
       "      <td>5.4052</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-13</th>\n",
       "      <td>5.3928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-14</th>\n",
       "      <td>5.4095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5754 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cambio     selic\n",
       "Date                        \n",
       "2000-01-03  1.8011  0.069186\n",
       "2000-01-04  1.8337       NaN\n",
       "2000-01-05  1.8544  0.069220\n",
       "2000-01-06  1.8461  0.069286\n",
       "2000-01-07  1.8281       NaN\n",
       "...            ...       ...\n",
       "2025-08-07  5.4638       NaN\n",
       "2025-08-11  5.4473       NaN\n",
       "2025-08-12  5.4052       NaN\n",
       "2025-08-13  5.3928       NaN\n",
       "2025-08-14  5.4095       NaN\n",
       "\n",
       "[5754 rows x 2 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambio.drop_duplicates(ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73577be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2000-03-17 \n",
      "End: 2025-08-17\n"
     ]
    }
   ],
   "source": [
    "start = '2000-03-17'\n",
    "\n",
    "end = dt.date.today()\n",
    "\n",
    "\n",
    "start_as_date = dt.datetime.strptime(start, '%Y-%m-%d').date() if type(start) == str else start\n",
    "\n",
    "end_as_date = dt.datetime.strptime(end, '%Y-%m-%d').date() if type(end) == str else end\n",
    "\n",
    "print(\"Start:\", start_as_date, \"\\nEnd:\", end_as_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23d69e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_years = (end_as_date - start_as_date).days / 365\n",
    "\n",
    "diff_years > 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae539e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "?dt.timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd9a6d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2000, 1, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(start_as_date - pd.offsets.YearBegin(1)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73db283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_start_year = (start_as_date - pd.offsets.YearBegin(1)).date()\n",
    "next_end_year = (end_as_date + pd.offsets.YearBegin(0)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d504438b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2000, 1, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_start_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b9a6ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2000-01-01 00:00:00'),\n",
       " Timestamp('2008-01-01 00:00:00'),\n",
       " Timestamp('2016-01-01 00:00:00'),\n",
       " Timestamp('2024-01-01 00:00:00'),\n",
       " '2025-07-17']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = pd.date_range(start=previous_start_year, end=next_end_year, freq='8YS', inclusive='left').to_list()\n",
    "intervals = intervals + [end]\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00a51f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000-01-01 00:00:00\n",
      "2008-01-01 00:00:00\n",
      "1\n",
      "2008-01-01 00:00:00\n",
      "2016-01-01 00:00:00\n",
      "2\n",
      "2016-01-01 00:00:00\n",
      "2024-01-01 00:00:00\n",
      "3\n",
      "2024-01-01 00:00:00\n",
      "2025-07-17\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'datetime.date' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     last_date \u001b[38;5;241m=\u001b[39m intervals[i_dates\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(last_date)\n\u001b[1;32m---> 13\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final_df, query], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m final_df\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[45], line 54\u001b[0m, in \u001b[0;36mget\u001b[1;34m(codes, start, end, last, multi, freq)\u001b[0m\n\u001b[0;32m     52\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m code \u001b[38;5;129;01min\u001b[39;00m _codes(codes):\n\u001b[1;32m---> 54\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(StringIO(text))\n\u001b[0;32m     56\u001b[0m     df \u001b[38;5;241m=\u001b[39m _format_df(df, code, freq)\n",
      "Cell \u001b[1;32mIn[45], line 96\u001b[0m, in \u001b[0;36mget_json\u001b[1;34m(code, start, end, last)\u001b[0m\n\u001b[0;32m     93\u001b[0m start_as_date \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(start, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdate() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(start) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m start\n\u001b[0;32m     94\u001b[0m end_as_date \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(end, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdate() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(end) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m end\n\u001b[1;32m---> 96\u001b[0m diff_years \u001b[38;5;241m=\u001b[39m (\u001b[43mend_as_date\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_as_date\u001b[49m)\u001b[38;5;241m.\u001b[39mdays \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m365\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# if diff_years > 8:  \u001b[39;00m\n\u001b[0;32m    102\u001b[0m urd \u001b[38;5;241m=\u001b[39m _get_url_and_payload(code, start, end, last)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'datetime.date' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "series = dict(cambio=1)\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for i_dates in range(len(intervals)-1):\n",
    "    print(i_dates)\n",
    "\n",
    "    first_date = intervals[i_dates]\n",
    "    print(first_date)\n",
    "\n",
    "    last_date = intervals[i_dates+1]\n",
    "    print(last_date)\n",
    "\n",
    "    query = get(series, start=first_date, end=last_date)\n",
    "\n",
    "    final_df = pd.concat([final_df, query], axis=0)\n",
    "\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df = final_df.loc[start:]\n",
    "final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fb948985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2001-01-01', '2009-01-01', '2017-01-01', '2025-01-01'], dtype='datetime64[ns]', freq='8YS-JAN')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start=start, end=end, freq='8YS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aff70ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_insample = 8\n",
    "n_periods = int((end_as_date - start_as_date).days/365)\n",
    "n_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ebc25bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_years/ (diff_years/years_insample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f8929a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1794520547945204"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_years / years_insample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fb0308f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1160.5"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end_as_date - start_as_date).days/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de03e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods/years = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7728ba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25*8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
